{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prelimenary Imports and ENV variable definitions\n",
    "import csv\n",
    "import os\n",
    "import yfinance as yf\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "load_dotenv()\n",
    "FILE_PATH = r\"./dataset/\" \n",
    "\n",
    "\n",
    "CIK_IDENTIFIERS = [\n",
    "    '0001720792',\n",
    "    '0001099281',\n",
    "    '0001079114',\n",
    "    '0001112520',\n",
    "    '0001641864',\n",
    "    '0000846222',\n",
    "    '0001709323',\n",
    "    '0000732905',\n",
    "    '0000883965',\n",
    "    '0001067983',\n",
    "    '0001061768',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the SUBMISSION table fetch a list of ACCESSION_NUMBER(s) using the CIK identifiers in table A-1 (Appendix).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picked_submissions = []\n",
    "\n",
    "prefixed = [filename for filename in os.listdir(FILE_PATH) if filename.startswith(\"SUBMISSION\")]\n",
    "print(prefixed)\n",
    "\n",
    "for file in prefixed:\n",
    "    with open(FILE_PATH + file, 'r', encoding='utf-8') as q:\n",
    "        for submission in csv.DictReader(q, delimiter=\"\\t\"):\n",
    "            if submission[\"CIK\"] in CIK_IDENTIFIERS:\n",
    "                picked_submissions.append(submission[\"ACCESSION_NUMBER\"])\n",
    "\n",
    "pprint(len(picked_submissions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the INFOTABLE fetch a list of NAMEOFISSUER(s) using the ACCESSION_NUMBER(s) created in (b). Use CUSIP(s) to map between brokers since it is unique where names differ slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_of_issuers = set()\n",
    "\n",
    "prefixed = [filename for filename in os.listdir(FILE_PATH) if filename.startswith(\"INFOTABLE\")]\n",
    "print(prefixed)\n",
    "\n",
    "for file in prefixed:\n",
    "    with open(FILE_PATH + file, 'r', encoding='utf-8') as q:\n",
    "        for entry in csv.DictReader(q, delimiter=\"\\t\"):\n",
    "            if entry[\"ACCESSION_NUMBER\"] in picked_submissions:\n",
    "                names_of_issuers.add(entry[\"CUSIP\"].upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to convert the CUSIP to tickers, we will do this using the polygon API to fetch info about a holding by it's CUSIP ID. \n",
    "\n",
    "Simply download the last 2 most recent file from https://www.sec.gov/data/foiadocsfailsdatahtm and store in dataset folder.\n",
    "\n",
    "In this step we lose about 12% of the dataset... Unsure if there is a better way to resolve this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = set()\n",
    "\n",
    "prefixed = [filename for filename in os.listdir(FILE_PATH) if filename.startswith(\"cnsfail\")]\n",
    "print(prefixed)\n",
    "\n",
    "for file in prefixed:\n",
    "    with open(FILE_PATH + file,'r') as f:\n",
    "        for entry in csv.DictReader(f, delimiter=\"|\"):\n",
    "            if entry['CUSIP'] in names_of_issuers: \n",
    "                tickers.add(entry['SYMBOL'])\n",
    "                names_of_issuers.remove(entry['CUSIP'])\n",
    "    \n",
    "pprint(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the rest of the ticker symbols to the set from the other datasets.\n",
    "\n",
    "Before anything delete the first 10 rows of the csv files {DIVB_holdings, HDV_holdings} as it messed up the parsing for DictReader.\n",
    "\n",
    "# TODO: Skip first 10 rows instead of delete for the automation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixed = [filename for filename in os.listdir(FILE_PATH) if \"holdings\" in filename]\n",
    "print(prefixed)\n",
    "\n",
    "for file in prefixed:\n",
    "    with open(FILE_PATH + 'DIVB_holdings.csv','r', encoding='utf-8-sig') as f:\n",
    "        for entry in csv.DictReader(f, delimiter=\",\"):\n",
    "            entry.keys()\n",
    "            tickers.add(entry[\"Ticker\"])\n",
    "        \n",
    "pprint(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From set A, remove all tickers that do not offer dividends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import HTTPError\n",
    "\n",
    "\n",
    "arr_A = list(tickers)\n",
    "\n",
    "ticker_objs = list(yf.Tickers(arr_A).tickers.values())\n",
    "arr_B = []\n",
    "for ticker in ticker_objs:\n",
    "    try:\n",
    "        if 'dividendRate' in ticker.info.keys():\n",
    "            arr_B.append(ticker.info[\"symbol\"])\n",
    "    except HTTPError:\n",
    "        print(f\"Ticker not found, removed from subset.\")\n",
    "        continue\n",
    "\n",
    "pprint(arr_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From subset (b) remove all names that have a high business risk, a debt to equity ratio greater than 1.5, sub-subset (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_objs = list(yf.Tickers(arr_B).tickers.values())\n",
    "\n",
    "\n",
    "arr_C = []\n",
    "\n",
    "for ticker in ticker_objs:\n",
    "    balance_sheet = list(ticker.balancesheet.to_dict().values())[0] # get most recent data\n",
    "    liabilities = balance_sheet['Total Liabilities Net Minority Interest']\n",
    "    assets = balance_sheet['Total Assets']\n",
    "    try:\n",
    "        debtToEquity = abs( liabilities / (assets - liabilities) )\n",
    "    except ZeroDivisionError:\n",
    "        print(ticker.info[\"symbol\"]) # if this is close to 0 then equity to debt ratio is near inf \n",
    "        continue                     # So we skip it.\n",
    "    if debtToEquity <= 1.5:\n",
    "        arr_C.append(ticker.info[\"symbol\"])\n",
    "\n",
    "print(len(arr_C))\n",
    "pprint(arr_C)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store subset into a file for the cfs module to reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'../cfs_module/subset_c.txt', 'w') as f:\n",
    "    f.write('\\n'.join(arr_C))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
