{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prelimenary Imports and ENV variable definitions\n",
    "import csv\n",
    "import os\n",
    "import yfinance as yf\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "load_dotenv()\n",
    "FILE_PATH = r\"./dataset/\" \n",
    "\n",
    "\n",
    "CIK_IDENTIFIERS = [\n",
    "    '0001720792',\n",
    "    '0001099281',\n",
    "    '0001079114',\n",
    "    '0001112520',\n",
    "    '0001641864',\n",
    "    '0000846222',\n",
    "    '0001709323',\n",
    "    '0000732905',\n",
    "    '0000883965',\n",
    "    '0001067983',\n",
    "    '0001061768',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading neccessary files, a lot of py magic here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "\n",
    "# Empty out directory\n",
    "files = [filename for filename in os.listdir(FILE_PATH) if not filename.startswith(\"README\")]\n",
    "for file in files:\n",
    "    os.remove(FILE_PATH+file)\n",
    "\n",
    "month = datetime.now().month\n",
    "quarter = 4 if int(month/4) == 0 else int(month/4)\n",
    "print(quarter)\n",
    "year = datetime.now().year\n",
    "\n",
    "fmonth = month-1\n",
    "fyear = year if fmonth != 0 else year-1\n",
    "if fmonth == 0:\n",
    "    fmonth = '12'\n",
    "elif fmonth < 10:\n",
    "    fmonth = '0' + str(fmonth)\n",
    "\n",
    "\n",
    "\n",
    "fails_deliver_url = f'https://www.sec.gov/files/data/fails-deliver-data/cnsfails{fyear}{fmonth}a.zip'\n",
    "url_high_div_etf = 'https://www.blackrock.com/us/individual/products/239563/ishares-high-dividend-etf/1464253357814.ajax?fileType=csv&fileName=HDV_holdings&dataType=fund'\n",
    "url_core_div_etf = 'https://www.ishares.com/us/products/291387/fund/1467271812596.ajax?fileType=csv&fileName=DIVB_holdings&dataType=fund'\n",
    "headers = {\n",
    "    'Host': 'www.sec.gov', 'Connection': 'close',\n",
    "    'Accept': 'application/json, text/javascript, */*; q=0.01', 'X-Requested-With': 'XMLHttpRequest',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36',\n",
    "}\n",
    "\n",
    "r = requests.get(url_high_div_etf, allow_redirects=True)\n",
    "with open(FILE_PATH + 'HDV_holdings.csv', 'wb+') as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "r = requests.get(url_core_div_etf, allow_redirects=True)\n",
    "with open(FILE_PATH + 'DIVB_holdings.csv', 'wb+') as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "with open(FILE_PATH + 'HDV_holdings.csv', 'r', encoding='utf-8-sig') as fp:\n",
    "    lines = fp.readlines()\n",
    "\n",
    "with open(FILE_PATH + 'HDV_holdings.csv', 'w', encoding='utf-8-sig') as fp:\n",
    "    for i, line in enumerate(lines):\n",
    "        if i<9: continue\n",
    "        fp.write(line)\n",
    "\n",
    "with open(FILE_PATH + 'DIVB_holdings.csv', 'r', encoding='utf-8-sig') as fp:\n",
    "    lines = fp.readlines()\n",
    "\n",
    "with open(FILE_PATH + 'DIVB_holdings.csv', 'w', encoding='utf-8-sig') as fp:\n",
    "    for i, line in enumerate(lines):\n",
    "        if i<9: continue\n",
    "        fp.write(line)\n",
    "\n",
    "r = requests.get(fails_deliver_url, headers=headers, allow_redirects=True)\n",
    "z = zipfile.ZipFile(BytesIO(r.content))\n",
    "z.extract(f'cnsfails{fyear}{fmonth}a', FILE_PATH)\n",
    "\n",
    "\n",
    "if quarter == 4: # q4 comes out in the new year so most recent data will be in last year for the 13f data.\n",
    "    year -= 1\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    if i > 0:\n",
    "        quarter -= 1\n",
    "        if quarter <= 0:\n",
    "            quarter = 4\n",
    "            year -= 1\n",
    "            \n",
    "    url = f'https://www.sec.gov/files/structureddata/data/form-13f-data-sets/{year}q{quarter}_form13f.zip'\n",
    "    r = requests.get(url, headers=headers, allow_redirects=True)\n",
    "    z = zipfile.ZipFile(BytesIO(r.content))\n",
    "    zipinfos = z.infolist()\n",
    "    for zipinfo in zipinfos:\n",
    "        if \"INFOTABLE\" in zipinfo.filename:\n",
    "            zipinfo.filename = f'INFOTABLE_{year}_q{quarter}.tsv'\n",
    "            z.extract(zipinfo, FILE_PATH)\n",
    "        elif \"SUBMISSION\" in zipinfo.filename:\n",
    "            zipinfo.filename = f'SUBMISSION_{year}_q{quarter}.tsv'\n",
    "            z.extract(zipinfo, FILE_PATH)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the SUBMISSION table fetch a list of ACCESSION_NUMBER(s) using the CIK identifiers in table A-1 (Appendix).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picked_submissions = []\n",
    "\n",
    "prefixed = [filename for filename in os.listdir(FILE_PATH) if filename.startswith(\"SUBMISSION\")]\n",
    "print(prefixed)\n",
    "\n",
    "for file in prefixed:\n",
    "    with open(FILE_PATH + file, 'r', encoding='utf-8') as q:\n",
    "        for submission in csv.DictReader(q, delimiter=\"\\t\"):\n",
    "            if submission[\"CIK\"] in CIK_IDENTIFIERS:\n",
    "                picked_submissions.append(submission[\"ACCESSION_NUMBER\"])\n",
    "\n",
    "pprint(len(picked_submissions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the INFOTABLE fetch a list of NAMEOFISSUER(s) using the ACCESSION_NUMBER(s) created in (b). Use CUSIP(s) to map between brokers since it is unique where names differ slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_of_issuers = set()\n",
    "\n",
    "prefixed = [filename for filename in os.listdir(FILE_PATH) if filename.startswith(\"INFOTABLE\")]\n",
    "print(prefixed)\n",
    "\n",
    "for file in prefixed:\n",
    "    with open(FILE_PATH + file, 'r', encoding='utf-8') as q:\n",
    "        for entry in csv.DictReader(q, delimiter=\"\\t\"):\n",
    "            if entry[\"ACCESSION_NUMBER\"] in picked_submissions:\n",
    "                names_of_issuers.add(entry[\"CUSIP\"].upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to convert the CUSIP to tickers, we will do this using the polygon API to fetch info about a holding by it's CUSIP ID. \n",
    "\n",
    "Simply download the last 2 most recent file from https://www.sec.gov/data/foiadocsfailsdatahtm and store in dataset folder.\n",
    "\n",
    "In this step we lose about 12% of the dataset... Unsure if there is a better way to resolve this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = set()\n",
    "\n",
    "prefixed = [filename for filename in os.listdir(FILE_PATH) if filename.startswith(\"cnsfail\")]\n",
    "print(prefixed)\n",
    "\n",
    "for file in prefixed:\n",
    "    with open(FILE_PATH + file,'r') as f:\n",
    "        for entry in csv.DictReader(f, delimiter=\"|\"):\n",
    "            if entry['CUSIP'] in names_of_issuers: \n",
    "                tickers.add(entry['SYMBOL'])\n",
    "                names_of_issuers.remove(entry['CUSIP'])\n",
    "    \n",
    "pprint(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the rest of the ticker symbols to the set from the other datasets.\n",
    "\n",
    "Before anything delete the first 10 rows of the csv files {DIVB_holdings, HDV_holdings} as it messed up the parsing for DictReader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixed = [filename for filename in os.listdir(FILE_PATH) if \"holdings\" in filename]\n",
    "print(prefixed)\n",
    "\n",
    "for file in prefixed:\n",
    "    with open(FILE_PATH + file,'r', encoding='utf-8-sig') as f:\n",
    "        for entry in csv.DictReader(f, delimiter=\",\"):\n",
    "            entry.keys()\n",
    "            tickers.add(entry[\"Ticker\"])\n",
    "        \n",
    "pprint(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From set A, remove all tickers that do not offer dividends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import HTTPError\n",
    "\n",
    "\n",
    "arr_A = list(tickers)\n",
    "\n",
    "ticker_objs = list(yf.Tickers(arr_A).tickers.values())\n",
    "arr_B = []\n",
    "for ticker in ticker_objs:\n",
    "    try:\n",
    "        if 'dividendRate' in ticker.info.keys():\n",
    "            arr_B.append(ticker.info[\"symbol\"])\n",
    "    except HTTPError:\n",
    "        print(f\"Ticker not found, removed from subset.\")\n",
    "        continue\n",
    "\n",
    "pprint(arr_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From subset (b) remove all names that have a high business risk, a debt to equity ratio greater than 1.5, sub-subset (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_objs = list(yf.Tickers(arr_B).tickers.values())\n",
    "\n",
    "\n",
    "arr_C = []\n",
    "\n",
    "for ticker in ticker_objs:\n",
    "    balance_sheet = list(ticker.balancesheet.to_dict().values())[0] # get most recent data\n",
    "    liabilities = balance_sheet['Total Liabilities Net Minority Interest']\n",
    "    assets = balance_sheet['Total Assets']\n",
    "    try:\n",
    "        debtToEquity = abs( liabilities / (assets - liabilities) )\n",
    "    except ZeroDivisionError:\n",
    "        print(ticker.info[\"symbol\"]) # if this is close to 0 then equity to debt ratio is near inf \n",
    "        continue                     # So we skip it.\n",
    "    if debtToEquity <= 1.5:\n",
    "        arr_C.append(ticker.info[\"symbol\"])\n",
    "\n",
    "print(len(arr_C))\n",
    "pprint(arr_C)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store subset into a file for the cfs module to reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'../cfs_module/subset_c.txt', 'w') as f:\n",
    "    f.write('\\n'.join(arr_C))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
